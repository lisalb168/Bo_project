{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Import data and Recover the 5-Fold Validation Indices](#Import-data-and-Recover-the-5-Fold-Validation-Indices)\n",
    "* [Function to log results](#Function-to-log-results)\n",
    "* [Use CountVectorizer to create feature matrix](#Use-CountVectorizer-to-create-feature-matrix)\n",
    "* [Classification Models](#Classification-Models)\n",
    "    * [1.1 RandomForest](#1.1-RandomForest)\n",
    "    * [1.2 Multinomial Naive Bayes](#1.2-Multinomial-Naive-Bayes)\n",
    "    * [1.3 LightGBM](#1.3-LightGBM)\n",
    "    * [1.4 Logistic Regression with regularizations](#1.4-Logistic-Regression-with-regularizations)\n",
    "* [Summary of models](#Summary-of-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} -c conda-forge lightgbm\n",
    "#!pip install afinn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow.python.keras import models, layers, optimizers\n",
    "#import tensorflow\n",
    "#from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import bz2\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "import re\n",
    "%matplotlib inline\n",
    "# Training and Testing data files are available in the \"../python notebook v1\" directory.\n",
    "# The following function finds all the .csv files in the project directory\n",
    "import os\n",
    "#def find_csv_filenames(path_to_dir, suffix=\".csv\"):\n",
    "#    filenames = os.listdir(path_to_dir)\n",
    "#    return [filename for filename in filenames if filename.endswith(suffix)]\n",
    "#filenames = find_csv_filenames(\"../python notebook v1\")\n",
    "#for name in filenames:\n",
    "#    print(name)\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "import statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import csv\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_log(cv_clf, modelname):\n",
    "    rlt_dict = {}\n",
    "\n",
    "    rlt_dict['best_estimator_'] = [cv_clf.best_estimator_]\n",
    "    rlt_dict['best_params_'] = [cv_clf.best_params_]\n",
    "    rlt_dict['best_score_'] = [cv_clf.best_score_]\n",
    "    rlt_dict['best_index_'] = [cv_clf.best_index_]\n",
    "\n",
    "    rlt_dict['candidate_params'] = [cv_clf.cv_results_['params']]\n",
    "    rlt_dict['mean_test_score'] = [cv_clf.cv_results_['mean_test_score']]\n",
    "    rlt_dict['std_test_score'] = [cv_clf.cv_results_['std_test_score']]\n",
    "    rlt_dict['mean_train_score'] = [cv_clf.cv_results_['mean_train_score']]\n",
    "    rlt_dict['std_train_score'] = [cv_clf.cv_results_['std_train_score']]\n",
    "\n",
    "    rlt_dict['split0_test_score'] = [cv_clf.cv_results_['split0_test_score']]\n",
    "    rlt_dict['split1_test_score'] = [cv_clf.cv_results_['split1_test_score']]\n",
    "    rlt_dict['split2_test_score'] = [cv_clf.cv_results_['split2_test_score']]\n",
    "    rlt_dict['split3_test_score'] = [cv_clf.cv_results_['split3_test_score']]\n",
    "    rlt_dict['split4_test_score'] = [cv_clf.cv_results_['split4_test_score']]\n",
    "\n",
    "    rlt_dict['split0_train_score'] = [cv_clf.cv_results_['split0_train_score']]\n",
    "    rlt_dict['split1_train_score'] = [cv_clf.cv_results_['split1_train_score']]\n",
    "    rlt_dict['split2_train_score'] = [cv_clf.cv_results_['split2_train_score']]\n",
    "    rlt_dict['split3_train_score'] = [cv_clf.cv_results_['split3_train_score']]\n",
    "    rlt_dict['split4_train_score'] = [cv_clf.cv_results_['split4_train_score']]\n",
    "\n",
    "    rlt_df = pd.DataFrame.from_dict(rlt_dict)\n",
    "    \n",
    "    filename = modelname + '_' + 'cv_rlt.csv'\n",
    "    rlt_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and Recover the 5-Fold Validation Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\", )\n",
    "y_train_0 = pd.read_csv(\"y_train.csv\", header=None)\n",
    "y_train = y_train_0[0]\n",
    "X_test = pd.read_csv(\"X_test.csv\", )\n",
    "y_test_0 = pd.read_csv(\"y_test.csv\", header=None)\n",
    "y_test = y_test_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (11640, 9)\n",
      "y_train shape:  (11640,)\n",
      "X_test shape:  (2911, 9)\n",
      "y_test shape:  (2911,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "kf.get_n_splits(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:  Train: [    0     1     2 ... 11636 11638 11639] Validation: [    3     6     7 ... 11619 11620 11637]\n",
      "Fold 2:  Train: [    1     3     5 ... 11637 11638 11639] Validation: [    0     2     4 ... 11591 11624 11629]\n",
      "Fold 3:  Train: [    0     1     2 ... 11637 11638 11639] Validation: [    8    33    35 ... 11631 11635 11636]\n",
      "Fold 4:  Train: [    0     2     3 ... 11636 11637 11638] Validation: [    1     5    18 ... 11632 11634 11639]\n",
      "Fold 5:  Train: [    0     1     2 ... 11636 11637 11639] Validation: [   13    16    17 ... 11628 11633 11638]\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    print(f\"Fold {i}: \", \"Train:\", train_index, \"Validation:\", val_index)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use CountVectorizer to create feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Create CountVectoroizer object\n",
    "vectorizer = CountVectorizer()\n",
    "# Generate matrix of word vectors\n",
    "X_train_matrix = vectorizer.fit_transform(X_train.text)\n",
    "X_test_matrix = vectorizer.transform(X_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11640, 7028)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>aal</th>\n",
       "      <th>aas</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>...</th>\n",
       "      <th>zambia</th>\n",
       "      <th>zcc</th>\n",
       "      <th>zero</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuke</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zz</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaaand  aadavantage  aadv  aadvantage  aal  aas  aback  abandon  \\\n",
       "0   0       0            0     0           0    0    0      0        0   \n",
       "1   0       0            0     0           0    0    0      0        0   \n",
       "2   0       0            0     0           0    0    0      0        0   \n",
       "3   0       0            0     0           0    0    0      0        0   \n",
       "4   0       0            0     0           0    0    0      0        0   \n",
       "\n",
       "   abandonment  ...  zambia  zcc  zero  zipper  zone  zoom  zuke  zurich  zz  \\\n",
       "0            0  ...       0    0     0       0     0     0     0       0   0   \n",
       "1            0  ...       0    0     0       0     0     0     0       0   0   \n",
       "2            0  ...       0    0     0       0     0     0     0       0   0   \n",
       "3            0  ...       0    0     0       0     0     0     0       0   0   \n",
       "4            0  ...       0    0     0       0     0     0     0       0   0   \n",
       "\n",
       "      ID  \n",
       "0   7908  \n",
       "1    538  \n",
       "2   4501  \n",
       "3  13982  \n",
       "4   6048  \n",
       "\n",
       "[5 rows x 7028 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert X_train_matrix into a DataFrame\n",
    "X_train_df = pd.DataFrame(X_train_matrix.toarray())\n",
    "# Map the column names to vocabulary \n",
    "X_train_df.columns = vectorizer.get_feature_names()\n",
    "# keep the original ID column\n",
    "X_train_df['ID'] = X_train.ID.to_list()\n",
    "print(X_train_df.shape)\n",
    "display(X_train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure after CountVectorizer, each row still corresponds to the same observation in the original train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point u cancel flight flight dca airline already cancel flightle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "airline        1\n",
       "already        1\n",
       "cancel         2\n",
       "dca            1\n",
       "flight         2\n",
       "flightle       1\n",
       "point          1\n",
       "ID          7908\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.text[0])\n",
    "X_train_df.iloc[0,:][X_train_df.iloc[0,:] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come get point buy rapid reward shopping site\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "buy            1\n",
       "come           1\n",
       "get            1\n",
       "point          1\n",
       "rapid          1\n",
       "reward         1\n",
       "shopping       1\n",
       "site           1\n",
       "ID          4501\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.text[2])\n",
    "X_train_df.iloc[2,:][X_train_df.iloc[2,:] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11640, 7035)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>aal</th>\n",
       "      <th>aas</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>...</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zz</th>\n",
       "      <th>ID</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>airline_company_American</th>\n",
       "      <th>airline_company_Delta</th>\n",
       "      <th>airline_company_Southwest</th>\n",
       "      <th>airline_company_US Airways</th>\n",
       "      <th>airline_company_United</th>\n",
       "      <th>airline_company_Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7035 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaaand  aadavantage  aadv  aadvantage  aal  aas  aback  abandon  \\\n",
       "0   0       0            0     0           0    0    0      0        0   \n",
       "1   0       0            0     0           0    0    0      0        0   \n",
       "2   0       0            0     0           0    0    0      0        0   \n",
       "3   0       0            0     0           0    0    0      0        0   \n",
       "4   0       0            0     0           0    0    0      0        0   \n",
       "\n",
       "   abandonment  ...  zurich  zz     ID  retweet_count  \\\n",
       "0            0  ...       0   0   7908            0.0   \n",
       "1            0  ...       0   0    538            0.0   \n",
       "2            0  ...       0   0   4501            0.0   \n",
       "3            0  ...       0   0  13982            0.0   \n",
       "4            0  ...       0   0   6048            0.0   \n",
       "\n",
       "   airline_company_American  airline_company_Delta  airline_company_Southwest  \\\n",
       "0                         0                      1                          0   \n",
       "1                         0                      0                          0   \n",
       "2                         0                      0                          1   \n",
       "3                         1                      0                          0   \n",
       "4                         0                      0                          1   \n",
       "\n",
       "   airline_company_US Airways  airline_company_United  \\\n",
       "0                           0                       0   \n",
       "1                           0                       1   \n",
       "2                           0                       0   \n",
       "3                           0                       0   \n",
       "4                           0                       0   \n",
       "\n",
       "   airline_company_Virgin America  \n",
       "0                               0  \n",
       "1                               0  \n",
       "2                               0  \n",
       "3                               0  \n",
       "4                               0  \n",
       "\n",
       "[5 rows x 7035 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_leftover = X_train.drop(['text'], axis=1)\n",
    "#display(X_train_leftover.head())\n",
    "#display(X_train_df.head())\n",
    "#print(\"Check the length are equal\", len(X_train_leftover) == len(X_train_df))\n",
    "\n",
    "# Get the full features by merging the 2 dataframes\n",
    "X_train_final = pd.merge(X_train_df, X_train_leftover, how='inner', on='ID')\n",
    "print(X_train_final.shape)\n",
    "display(X_train_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>aal</th>\n",
       "      <th>aas</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>...</th>\n",
       "      <th>zuke</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zz</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>airline_company_American</th>\n",
       "      <th>airline_company_Delta</th>\n",
       "      <th>airline_company_Southwest</th>\n",
       "      <th>airline_company_US Airways</th>\n",
       "      <th>airline_company_United</th>\n",
       "      <th>airline_company_Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7034 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaaand  aadavantage  aadv  aadvantage  aal  aas  aback  abandon  \\\n",
       "0   0       0            0     0           0    0    0      0        0   \n",
       "1   0       0            0     0           0    0    0      0        0   \n",
       "2   0       0            0     0           0    0    0      0        0   \n",
       "3   0       0            0     0           0    0    0      0        0   \n",
       "4   0       0            0     0           0    0    0      0        0   \n",
       "\n",
       "   abandonment  ...  zuke  zurich  zz  retweet_count  \\\n",
       "0            0  ...     0       0   0            0.0   \n",
       "1            0  ...     0       0   0            0.0   \n",
       "2            0  ...     0       0   0            0.0   \n",
       "3            0  ...     0       0   0            0.0   \n",
       "4            0  ...     0       0   0            0.0   \n",
       "\n",
       "   airline_company_American  airline_company_Delta  airline_company_Southwest  \\\n",
       "0                         0                      1                          0   \n",
       "1                         0                      0                          0   \n",
       "2                         0                      0                          1   \n",
       "3                         1                      0                          0   \n",
       "4                         0                      0                          1   \n",
       "\n",
       "   airline_company_US Airways  airline_company_United  \\\n",
       "0                           0                       0   \n",
       "1                           0                       1   \n",
       "2                           0                       0   \n",
       "3                           0                       0   \n",
       "4                           0                       0   \n",
       "\n",
       "   airline_company_Virgin America  \n",
       "0                               0  \n",
       "1                               0  \n",
       "2                               0  \n",
       "3                               0  \n",
       "4                               0  \n",
       "\n",
       "[5 rows x 7034 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop the ID column to prepare for fitting models\n",
    "X_train_no_ID = X_train_final.drop(['ID'], axis=1)\n",
    "display(X_train_no_ID.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed in 34.726754 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "\n",
    "niter, verbose, random_state = [5, 0, 123] \n",
    "param_space = {'n_estimators': range(100,500,100), 'max_depth': range(1,20)}\n",
    "\n",
    "clf = RandomForestClassifier(random_state=random_state)\n",
    "cv_clf = RandomizedSearchCV(clf, param_space, cv=kf, n_iter=niter, return_train_score=True, \n",
    "                            verbose=verbose, n_jobs=-1) \n",
    "cv_clf.fit(X_train_no_ID, y_train)\n",
    "\n",
    "print('completed in {} s'.format(time.process_time() - start))\n",
    "\n",
    "# write out results\n",
    "model_log(cv_clf, 'RF_CountVectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Five candidate parameters are:  [{'n_estimators': 400, 'max_depth': 18}, {'n_estimators': 100, 'max_depth': 17}, {'n_estimators': 100, 'max_depth': 14}, {'n_estimators': 300, 'max_depth': 6}, {'n_estimators': 200, 'max_depth': 10}]\n",
      "2. Best number of trees and depth are: 400 and 18\n",
      "3. Best average CV validation score is:  0.638487972508591\n",
      "4. Average CV validation score:  [0.63848797 0.6371134  0.63213058 0.62989691 0.63006873]\n",
      "5. Standard Deviation of CV validation score:  [0.0054511  0.00490067 0.00816196 0.00673509 0.00683732]\n",
      "6. Average CV training score:  [0.6425043  0.64140893 0.63438574 0.62989691 0.63026203]\n",
      "7. Standard Deviation of CV training score:  [0.00151261 0.00368728 0.00216765 0.00168377 0.00146458]\n",
      "1st fold validation score:  [0.63530928 0.63445017 0.63101375 0.62843643 0.62843643]\n",
      "2nd fold validation score:  [0.63745704 0.63745704 0.62972509 0.62800687 0.62843643]\n",
      "3rd fold validation score:  [0.64690722 0.64647766 0.64561856 0.63960481 0.64003436]\n",
      "4th fold validation score:  [0.63101375 0.63316151 0.62027491 0.61941581 0.61941581]\n",
      "5th fold validation score:  [0.64175258 0.63402062 0.63402062 0.63402062 0.63402062]\n",
      "1st fold training score:  [0.64314863 0.64368557 0.6342354  0.63026203 0.63026203]\n",
      "2nd fold training score:  [0.64271907 0.64293385 0.63445017 0.63036942 0.63112113]\n",
      "3rd fold training score:  [0.64121564 0.6397122  0.63670533 0.62746993 0.62854381]\n",
      "4th fold training score:  [0.64486684 0.64561856 0.636061   0.63251718 0.63251718]\n",
      "5th fold training score:  [0.64057131 0.6350945  0.6304768  0.62886598 0.62886598]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "result = pd.read_csv('RF_CountVectorizer_cv_rlt.csv')\n",
    "candidate_params = ast.literal_eval(result.candidate_params.values[0])\n",
    "print(\"1. Five candidate parameters are: \", candidate_params)\n",
    "best_n = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['n_estimators']\n",
    "best_d = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['max_depth']\n",
    "print(\"2. Best number of trees and depth are: {} and {}\".format(best_n, best_d))\n",
    "best_score_rf = result.best_score_.values[0]\n",
    "print(\"3. Best average CV validation score is: \", best_score_rf)\n",
    "mean_test_score = result.mean_test_score.values[0]\n",
    "print(\"4. Average CV validation score: \", mean_test_score)\n",
    "std_test_score = result.std_test_score.values[0]\n",
    "print(\"5. Standard Deviation of CV validation score: \", std_test_score)\n",
    "mean_train_score = result.mean_train_score.values[0]\n",
    "print(\"6. Average CV training score: \", mean_train_score)\n",
    "std_train_score = result.std_train_score.values[0]\n",
    "print(\"7. Standard Deviation of CV training score: \", std_train_score)\n",
    "\n",
    "print(\"1st fold validation score: \", result.split0_test_score.values[0])\n",
    "print(\"2nd fold validation score: \", result.split1_test_score.values[0])\n",
    "print(\"3rd fold validation score: \", result.split2_test_score.values[0])\n",
    "print(\"4th fold validation score: \", result.split3_test_score.values[0])\n",
    "print(\"5th fold validation score: \", result.split4_test_score.values[0])\n",
    "print(\"1st fold training score: \", result.split0_train_score.values[0])\n",
    "print(\"2nd fold training score: \", result.split1_train_score.values[0])\n",
    "print(\"3rd fold training score: \", result.split2_train_score.values[0])\n",
    "print(\"4th fold training score: \", result.split3_train_score.values[0])\n",
    "print(\"5th fold training score: \", result.split4_train_score.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification performance on the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pd.read_csv('RF_CountVectorizer_cv_rlt.csv')\n",
    "best_n = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['n_estimators']\n",
    "best_d = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['max_depth']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = best_n, max_depth = best_d, \n",
    "                             bootstrap=True, class_weight=None, criterion='gini',\n",
    "                             max_features='auto', max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                             min_samples_leaf=1, min_samples_split=2,\n",
    "                             min_weight_fraction_leaf=0.0, n_jobs=None,\n",
    "                             oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
    "\n",
    "clf.fit(X_train_no_ID, y_train)\n",
    "\n",
    "preds = clf.predict(X_train_no_ID)\n",
    "probs = clf.predict_proba(X_train_no_ID)\n",
    "\n",
    "# plot top 10 features of the training set\n",
    "M = 10\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "features = X_train_no_ID.columns\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(M), importances[indices][-M:], color='b', align='center')\n",
    "plt.yticks(range(M), [features[i] for i in indices[-M:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Confusion Matrix for the training data is: \n",
      " [[ 109    0 2332]\n",
      " [   5   29 1833]\n",
      " [   9    0 7323]]\n",
      "2. Training accuracy: 0.640979\n",
      "3. Training report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.04      0.09      2441\n",
      "           1       1.00      0.02      0.03      1867\n",
      "           2       0.64      1.00      0.78      7332\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     11640\n",
      "   macro avg       0.84      0.35      0.30     11640\n",
      "weighted avg       0.75      0.64      0.51     11640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#preds = clf.predict(X_train_no_ID)\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_train, preds, labels=None, sample_weight=None)\n",
    "report = classification_report(y_train, preds)\n",
    "#probs = clf.predict_proba(X_train_no_ID)\n",
    "accuracy = float(np.sum(preds==y_train))/y_train.shape[0] \n",
    "\n",
    "print(\"1. Confusion Matrix for the training data is: \\n\", confusion_matrix)\n",
    "print(\"2. Training accuracy: %f\" % (accuracy))\n",
    "print(\"3. Training report: \", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average training and validation scores show slight overfitting of the Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Training scores are:  [0.8393470790378007, 0.834729381443299, 0.8397766323024055, 0.8395618556701031, 0.8441795532646048]\n",
      "Average Training score is: 0.83952\n",
      "5-Fold Validation scores are:  [0.7628865979381443, 0.7658934707903781, 0.7598797250859106, 0.7697594501718213, 0.7439862542955327]\n",
      "Average validation score is: 0.76048\n"
     ]
    }
   ],
   "source": [
    "# Import MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB # Create MultinomialNB object\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train clf on 5 fold data\n",
    "val_accuracy = []\n",
    "train_acc = []\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_5cv, X_val_5cv = X_train_no_ID.iloc[train_index,:], X_train_no_ID.iloc[val_index,:]\n",
    "    y_train_5cv, y_val_5cv = y_train[train_index], y_train[val_index]\n",
    "    clf.fit(X_train_5cv, y_train_5cv)\n",
    "    train_acc.append(clf.score(X_train_5cv, y_train_5cv))\n",
    "    val_accuracy.append(clf.score(X_val_5cv, y_val_5cv))\n",
    "print(\"5-Fold Training scores are: \", train_acc)\n",
    "mean_train_score = np.mean(train_acc)\n",
    "print(\"Average Training score is: {:.5f}\".format(mean_train_score))\n",
    "print(\"5-Fold Validation scores are: \", val_accuracy)\n",
    "mean_validation_score_NB = np.mean(val_accuracy)\n",
    "print(\"Average validation score is: {:.5f}\".format(mean_validation_score_NB))\n",
    "\n",
    "# write average validation score to csv file\n",
    "rlt_dict = {}\n",
    "rlt_dict['Average_val_score'] = [mean_validation_score_NB]\n",
    "rlt_df = pd.DataFrame.from_dict(rlt_dict)\n",
    "filename = \"NB_CountVectorizer_cv_rlt.csv\"\n",
    "rlt_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification performance on the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.838144\n",
      "Confusion Matrix for training set is: \n",
      " [[1424  122  895]\n",
      " [ 104 1378  385]\n",
      " [ 252  126 6954]]\n",
      "Classification Report for training set is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.58      0.67      2441\n",
      "           1       0.85      0.74      0.79      1867\n",
      "           2       0.84      0.95      0.89      7332\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     11640\n",
      "   macro avg       0.83      0.76      0.79     11640\n",
      "weighted avg       0.84      0.84      0.83     11640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_no_ID, y_train)\n",
    "\n",
    "# Compute accuracy on entire training set\n",
    "train_accuracy = clf.score(X_train_no_ID, y_train) \n",
    "print(\"Training accuracy: %f\" % (train_accuracy))\n",
    "\n",
    "# create confusion matrix and classification report for the training data\n",
    "preds = clf.predict(X_train_no_ID)\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_train, preds, labels=None, sample_weight=None)\n",
    "report = classification_report(y_train, preds)\n",
    "probs = clf.predict_proba(X_train_no_ID)\n",
    "print(\"Confusion Matrix for training set is: \\n\", confusion_matrix)\n",
    "print(\"Classification Report for training set is: \\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed in 8.624207902999999 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "\n",
    "niter, verbose, random_state = [5, 0, 123] \n",
    "param_space = {'n_estimators': range(100,500,100), 'learning_rate': [0.01,0.1,0.5], \n",
    "               'max_depth': range(1,5)}\n",
    "\n",
    "clf = LGBMClassifier(colsample_bytree=1, subsample=1, reg_alpha=0, reg_lambda=1, verbose=verbose,\n",
    "                     random_state=random_state)\n",
    "cv_clf = RandomizedSearchCV(clf, param_space, cv=kf, n_iter=niter, return_train_score=True, scoring='accuracy', \n",
    "                            verbose=verbose, n_jobs = -1)  \n",
    "cv_clf.fit(X_train_no_ID, y_train)\n",
    "\n",
    "print('completed in {} s'.format(time.process_time() - start))\n",
    "\n",
    "# write out results\n",
    "model_log(cv_clf, 'GBM_CountVectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Five candidate parameters are:  [{'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1}, {'n_estimators': 400, 'max_depth': 2, 'learning_rate': 0.01}, {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.1}, {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.1}, {'n_estimators': 400, 'max_depth': 1, 'learning_rate': 0.5}]\n",
      "2. Best number of trees, learning rate and depth are: 400, 0.5 and 1\n",
      "3. Best average CV validation score is:  0.7644329896907216\n",
      "4. Average CV validation score:  [0.76065292 0.68582474 0.75945017 0.75635739 0.76443299]\n",
      "5. Standard Deviation of CV validation score:  [0.00513599 0.00677333 0.00419997 0.00469296 0.00403506]\n",
      "6. Average CV training score:  [0.78436426 0.68651203 0.78191581 0.77300258 0.79018471]\n",
      "7. Standard Deviation of CV training score:  [0.00156507 0.00171606 0.00100372 0.00161068 0.00136919]\n",
      "1st fold validation score:  [0.75687285 0.67482818 0.75773196 0.75257732 0.7628866 ]\n",
      "2nd fold validation score:  [0.76718213 0.68685567 0.7628866  0.76116838 0.7693299 ]\n",
      "3rd fold validation score:  [0.75945017 0.69458763 0.7637457  0.76202749 0.76460481]\n",
      "4th fold validation score:  [0.75386598 0.68256014 0.75214777 0.75       0.75773196]\n",
      "5th fold validation score:  [0.76589347 0.6902921  0.76073883 0.75601375 0.76761168]\n",
      "1st fold training score:  [0.78661942 0.68846649 0.78318299 0.77255155 0.79091495]\n",
      "2nd fold training score:  [0.78232388 0.6875     0.78092784 0.7729811  0.79177405]\n",
      "3rd fold training score:  [0.78329038 0.68395619 0.78060567 0.77040378 0.78833763]\n",
      "4th fold training score:  [0.78393471 0.68760739 0.78210911 0.77373282 0.78876718]\n",
      "5th fold training score:  [0.78565292 0.68503007 0.78275344 0.77534364 0.79112973]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "result = pd.read_csv('GBM_CountVectorizer_cv_rlt.csv')\n",
    "candidate_params = ast.literal_eval(result.candidate_params.values[0])\n",
    "print(\"1. Five candidate parameters are: \", candidate_params)\n",
    "best_n = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['n_estimators']\n",
    "best_d = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['max_depth']\n",
    "best_lr = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['learning_rate']\n",
    "print(\"2. Best number of trees, learning rate and depth are: {}, {} and {}\".format(best_n, best_lr, best_d))\n",
    "best_score_LGB = result.best_score_.values[0]\n",
    "print(\"3. Best average CV validation score is: \", best_score_LGB)\n",
    "mean_test_score = result.mean_test_score.values[0]\n",
    "print(\"4. Average CV validation score: \", mean_test_score)\n",
    "std_test_score = result.std_test_score.values[0]\n",
    "print(\"5. Standard Deviation of CV validation score: \", std_test_score)\n",
    "mean_train_score = result.mean_train_score.values[0]\n",
    "print(\"6. Average CV training score: \", mean_train_score)\n",
    "std_train_score = result.std_train_score.values[0]\n",
    "print(\"7. Standard Deviation of CV training score: \", std_train_score)\n",
    "\n",
    "print(\"1st fold validation score: \", result.split0_test_score.values[0])\n",
    "print(\"2nd fold validation score: \", result.split1_test_score.values[0])\n",
    "print(\"3rd fold validation score: \", result.split2_test_score.values[0])\n",
    "print(\"4th fold validation score: \", result.split3_test_score.values[0])\n",
    "print(\"5th fold validation score: \", result.split4_test_score.values[0])\n",
    "print(\"1st fold training score: \", result.split0_train_score.values[0])\n",
    "print(\"2nd fold training score: \", result.split1_train_score.values[0])\n",
    "print(\"3rd fold training score: \", result.split2_train_score.values[0])\n",
    "print(\"4th fold training score: \", result.split3_train_score.values[0])\n",
    "print(\"5th fold training score: \", result.split4_train_score.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification performance on the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pd.read_csv('GBM_CountVectorizer_cv_rlt.csv')\n",
    "best_n = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['n_estimators']\n",
    "best_d = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['max_depth']\n",
    "best_lr = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['learning_rate']\n",
    "\n",
    "clf = LGBMClassifier(n_estimators=best_n, learning_rate=best_lr, max_depth=best_d, \n",
    "                     boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
    "                     importance_type='split', min_child_samples=20, min_child_weight=0.001, \n",
    "                     min_split_gain=0.0, n_jobs=-1, num_leaves=31, objective=None, random_state=None, \n",
    "                     reg_alpha=0, reg_lambda=1, silent=True, subsample=1, subsample_for_bin=200000, \n",
    "                     subsample_freq=0, verbose=0)\n",
    "\n",
    "clf.fit(X_train_no_ID, y_train)\n",
    "\n",
    "preds = clf.predict(X_train_no_ID)\n",
    "probs = clf.predict_proba(X_train_no_ID)\n",
    "\n",
    "# plot top 10 features of the training set\n",
    "M = 10\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "features = X_train_no_ID.columns\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(M), importances[indices][-M:], color='b', align='center')\n",
    "plt.yticks(range(M), [features[i] for i in indices[-M:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Confusion Matrix for the training data is: \n",
      " [[1128  177 1136]\n",
      " [ 201 1199  467]\n",
      " [ 310  163 6859]]\n",
      "2. Training accuracy: 0.789175\n",
      "3. Training report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.46      0.55      2441\n",
      "           1       0.78      0.64      0.70      1867\n",
      "           2       0.81      0.94      0.87      7332\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     11640\n",
      "   macro avg       0.76      0.68      0.71     11640\n",
      "weighted avg       0.78      0.79      0.78     11640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_train_no_ID)\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_train, preds, labels=None, sample_weight=None)\n",
    "report = classification_report(y_train, preds)\n",
    "probs = clf.predict_proba(X_train_no_ID)\n",
    "accuracy = float(np.sum(preds==y_train))/y_train.shape[0] \n",
    "\n",
    "print(\"1. Confusion Matrix for the training data is: \\n\", confusion_matrix)\n",
    "print(\"2. Training accuracy: %f\" % (accuracy))\n",
    "print(\"3. Training report: \", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Logistic Regression with regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed in 360.88216224999996 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "\n",
    "niter, verbose, random_state = [5, 0, 123] \n",
    "param_space = {'penalty': ['l1','l2'], 'C': [0.005, 0.01, 0.1, 1, 10, 100, 200]}\n",
    "        \n",
    "clf = LogisticRegression(random_state=random_state, solver='saga', multi_class='multinomial')\n",
    "cv_clf = RandomizedSearchCV(clf, param_space, cv=kf, n_iter=niter, return_train_score=True, scoring='accuracy', \n",
    "                            verbose=verbose, n_jobs = -1) \n",
    "cv_clf.fit(X_train_no_ID, y_train)\n",
    "\n",
    "print('completed in {} s'.format(time.process_time() - start))\n",
    "\n",
    "# write out results\n",
    "model_log(cv_clf, 'logistic_CountVectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Five candidate parameters are:  [{'penalty': 'l2', 'C': 200}, {'penalty': 'l1', 'C': 10}, {'penalty': 'l2', 'C': 1}, {'penalty': 'l2', 'C': 0.005}, {'penalty': 'l2', 'C': 10}]\n",
      "2. Best C and penalty are: 10 and l1\n",
      "3. Best average CV validation score is:  0.7879725085910653\n",
      "4. Average CV validation score:  [0.78453608 0.78797251 0.78402062 0.6967354  0.78462199]\n",
      "5. Standard Deviation of CV validation score:  [0.0049097  0.00619272 0.00480178 0.00520451 0.00491721]\n",
      "6. Average CV training score:  [0.84748711 0.86793385 0.8455756  0.70165378 0.84735825]\n",
      "7. Standard Deviation of CV training score:  [0.00980554 0.01057814 0.00894951 0.00178717 0.00976433]\n",
      "1st fold validation score:  [0.78479381 0.78694158 0.78608247 0.69501718 0.78522337]\n",
      "2nd fold validation score:  [0.79209622 0.7959622  0.79166667 0.69630584 0.79209622]\n",
      "3rd fold validation score:  [0.78522337 0.78994845 0.7830756  0.70274914 0.78522337]\n",
      "4th fold validation score:  [0.78393471 0.78994845 0.78221649 0.68814433 0.78393471]\n",
      "5th fold validation score:  [0.7766323  0.77706186 0.77706186 0.70146048 0.7766323 ]\n",
      "1st fold training score:  [0.8667311  0.88896048 0.86318729 0.70317869 0.86651632]\n",
      "2nd fold training score:  [0.84149485 0.86265034 0.83945447 0.69866838 0.84106529]\n",
      "3rd fold training score:  [0.84160223 0.86189863 0.84117268 0.70339347 0.84160223]\n",
      "4th fold training score:  [0.84128007 0.86136168 0.83999141 0.70060137 0.84138746]\n",
      "5th fold training score:  [0.84632732 0.86479811 0.84407216 0.70242698 0.84621993]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "result = pd.read_csv('logistic_CountVectorizer_cv_rlt.csv')\n",
    "candidate_params = ast.literal_eval(result.candidate_params.values[0])\n",
    "print(\"1. Five candidate parameters are: \", candidate_params)\n",
    "best_c = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['C']\n",
    "best_penalty = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['penalty']\n",
    "print(\"2. Best C and penalty are: {} and {}\".format(best_c, best_penalty))\n",
    "best_score_Logistic = result.best_score_.values[0]\n",
    "print(\"3. Best average CV validation score is: \", best_score_Logistic)\n",
    "mean_test_score = result.mean_test_score.values[0]\n",
    "print(\"4. Average CV validation score: \", mean_test_score)\n",
    "std_test_score = result.std_test_score.values[0]\n",
    "print(\"5. Standard Deviation of CV validation score: \", std_test_score)\n",
    "mean_train_score = result.mean_train_score.values[0]\n",
    "print(\"6. Average CV training score: \", mean_train_score)\n",
    "std_train_score = result.std_train_score.values[0]\n",
    "print(\"7. Standard Deviation of CV training score: \", std_train_score)\n",
    "\n",
    "print(\"1st fold validation score: \", result.split0_test_score.values[0])\n",
    "print(\"2nd fold validation score: \", result.split1_test_score.values[0])\n",
    "print(\"3rd fold validation score: \", result.split2_test_score.values[0])\n",
    "print(\"4th fold validation score: \", result.split3_test_score.values[0])\n",
    "print(\"5th fold validation score: \", result.split4_test_score.values[0])\n",
    "print(\"1st fold training score: \", result.split0_train_score.values[0])\n",
    "print(\"2nd fold training score: \", result.split1_train_score.values[0])\n",
    "print(\"3rd fold training score: \", result.split2_train_score.values[0])\n",
    "print(\"4th fold training score: \", result.split3_train_score.values[0])\n",
    "print(\"5th fold training score: \", result.split4_train_score.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification performance on the entire training set, looks like there is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Confusion Matrix for the training data is: \n",
      " [[1680  142  619]\n",
      " [ 189 1423  255]\n",
      " [ 302  114 6916]]\n",
      "2. Training accuracy: 0.860739\n",
      "3. Training report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73      2441\n",
      "           1       0.85      0.76      0.80      1867\n",
      "           2       0.89      0.94      0.91      7332\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     11640\n",
      "   macro avg       0.84      0.80      0.82     11640\n",
      "weighted avg       0.86      0.86      0.86     11640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv('logistic_CountVectorizer_cv_rlt.csv')\n",
    "best_c = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['C']\n",
    "best_penalty = ast.literal_eval(re.search('({.+})', result.best_params_.values[0]).group(0))['penalty']\n",
    "\n",
    "clf = LogisticRegression(C=best_c, class_weight=None, dual=False, fit_intercept=True,\n",
    "                         intercept_scaling=1, max_iter=100, solver='saga', multi_class='multinomial',\n",
    "                         n_jobs=None, penalty=best_penalty, random_state=123, \n",
    "                         tol=0.0001, verbose=0, warm_start=False)\n",
    "clf.fit(X_train_no_ID, y_train)\n",
    "\n",
    "preds = clf.predict(X_train_no_ID)\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_train, preds, labels=None, sample_weight=None)\n",
    "report = classification_report(y_train, preds)\n",
    "probs = clf.predict_proba(X_train_no_ID)\n",
    "accuracy = float(np.sum(preds==y_train))/y_train.shape[0] \n",
    "\n",
    "print(\"1. Confusion Matrix for the training data is: \\n\", confusion_matrix)\n",
    "print(\"2. Training accuracy: %f\" % (accuracy))\n",
    "print(\"3. Training report: \", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model selected based on average validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForest': 0.638487972508591, 'Naive Bayes': 0.7604810996563574, 'LightGBM': 0.7644329896907216, 'Logistic Regression': 0.7879725085910653}\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv('RF_CountVectorizer_cv_rlt.csv')\n",
    "best_score_rf = result.best_score_.values[0]\n",
    "\n",
    "result = pd.read_csv('NB_CountVectorizer_cv_rlt.csv')\n",
    "mean_validation_score_NB = result.Average_val_score[0]\n",
    "\n",
    "result = pd.read_csv('GBM_CountVectorizer_cv_rlt.csv')\n",
    "best_score_LGB = result.best_score_.values[0]\n",
    "\n",
    "result = pd.read_csv('logistic_CountVectorizer_cv_rlt.csv')\n",
    "best_score_Logistic = result.best_score_.values[0]\n",
    "\n",
    "validation_scores = {'RandomForest': best_score_rf, 'Naive Bayes': mean_validation_score_NB, \n",
    "                     'LightGBM': best_score_LGB, 'Logistic Regression': best_score_Logistic}\n",
    "print(validation_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
